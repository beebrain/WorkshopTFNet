{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\envs\\py36tf\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7422ea296814>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\py36tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\py36tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\py36tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\py36tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\py36tf\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Load example Data \n",
    "mnist = input_data.read_data_sets('MNIST-data', one_hot=True,reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define  inital Weight and Bias function\n",
    "def weightVariable(shapeW):\n",
    "    init = tf.truncated_normal(shape=shapeW,stddev=0.1)\n",
    "    return tf.Variable(initial_value=init)\n",
    "\n",
    "def biasVariable(shapeB):\n",
    "    init = tf.constant(0.5,shape=shapeB)\n",
    "    return tf.Variable(initial_value=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define convolution Function \n",
    "def con2D(inputX,weightF,strite_num = 1):\n",
    "    # tf.nn.conv2d( input, filter, strides, padding, use_cudnn_on_gpu=True,\n",
    "    #               data_format='NHWC', dilations=[1, 1, 1, 1], name=None)\n",
    "    # NHWC mean => [batch, height, width, channels]\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(input=inputX,filter=weightF,\n",
    "                        strides=[1,strite_num,strite_num,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Maxpool Function\n",
    "def maxPool(inputX,size=2,strite_num = 2):\n",
    "    # tf.nn.max_pool(value,ksize,strides,padding,data_format='NHWC',name=None)\n",
    "    return tf.nn.max_pool(value=inputX,ksize=[1,size,size,1],\n",
    "                          strides=[1,strite_num,strite_num,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create placeholder xs and ys , xs is an image input and ys is a label of class\n",
    "#[optional]reshape for make sure the input is 28*28\n",
    "tf.reset_default_graph()   # clear all graph\n",
    "\n",
    "xs = tf.placeholder(shape=[None,28,28,1],dtype=tf.float32,name=\"inputX\")\n",
    "ys = tf.placeholder(shape=[None,10],dtype=tf.float32,name=\"labelY\")\n",
    "xImage = tf.reshape(xs,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv1\n",
    "numFilter_1 = 32\n",
    "filter_con1 = weightVariable([5,5,1,numFilter_1]) # patch 5x5, in size 1, out size 32\n",
    "bias_con1 = biasVariable([numFilter_1])\n",
    "feature_con1 = tf.nn.bias_add(con2D(inputX=xImage,weightF=filter_con1,strite_num=1),bias_con1)\n",
    "feature_con1 = tf.nn.relu(feature_con1)   #relu Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxpool1\n",
    "pool1 = maxPool(feature_con1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2\n",
    "numFilter_2 = 64\n",
    "filter_con2 = weightVariable([5,5,numFilter_1,numFilter_2])\n",
    "bias_con2 = biasVariable([numFilter_2])\n",
    "feature_con2 = tf.nn.bias_add(con2D(inputX=pool1,weightF=filter_con2,strite_num=1),bias_con2)\n",
    "feature_con2 = tf.nn.relu(feature_con2) #relu Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maxpool2\n",
    "pool2 = maxPool(inputX=feature_con2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToTal Element = 3136\n"
     ]
    }
   ],
   "source": [
    "#FullyConnected    #3136->512->512->10\n",
    "layer_shape = pool2.get_shape()\n",
    "TotalElement = layer_shape[1:4].num_elements()\n",
    "print(\"ToTal Element = {:d}\".format(TotalElement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFconnect = tf.reshape(pool2,[-1,TotalElement])\n",
    "wF1 = weightVariable(shapeW=[TotalElement,512])\n",
    "bF1 = biasVariable(shapeB=[512])\n",
    "FF_feature_1 = tf.matmul(FFconnect,wF1)+bF1\n",
    "FF_feature_1 = tf.nn.relu(FF_feature_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wF2 = weightVariable(shapeW=[512,10])\n",
    "bF2 = biasVariable(shapeB=[10])\n",
    "FF_feature_2 = tf.matmul(FF_feature_1,wF2)+bF2\n",
    "\n",
    "prediction_out = tf.nn.softmax(FF_feature_2,name=\"Y_pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define cross entropy\n",
    "$$H_{y'}(y) = - \\sum_{i}  y'_i \\times log(y_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost =tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction_out),reduction_indices=1),name=\"cost\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create accuracy tensor\n",
    "y_predic_cls = tf.argmax(prediction_out,axis=1)\n",
    "y_true_cls = tf.argmax(ys, axis=1)\n",
    "correct_prediction = tf.equal(y_predic_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"ACC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Information\n",
    "tf.summary.scalar('cross_entropy', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 Batch : acc = 0.1000 loss = 5.3227 | Test acc = 0.0773 loss = 5.9389\n",
      "Model saved improve from: 0.000000  to 0.077300\n",
      "Step : 100 Batch : acc = 0.7700 loss = 0.7537 | Test acc = 0.7623 loss = 0.7787\n",
      "Model saved improve from: 0.077300  to 0.762300\n",
      "Step : 200 Batch : acc = 0.8300 loss = 0.5530 | Test acc = 0.8557 loss = 0.4759\n",
      "Model saved improve from: 0.762300  to 0.855700\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "initValue = tf.global_variables_initializer()\n",
    "sess.run(initValue)\n",
    "train_summary_file = tf.summary.FileWriter(\"Log/train\",graph=sess.graph)\n",
    "test_summary_file  = tf.summary.FileWriter(\"Log/test\",graph=sess.graph)\n",
    "#training section\n",
    "\n",
    "acc_val = 0\n",
    "for i in range(300):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)  #get data from mnist \n",
    "    _,summary_out  = sess.run([optimizer,summary_op], feed_dict={xs: batch_xs, ys: batch_ys})  #feed data to tensorflow  we have 2 branch optimizer and summary_op\n",
    "    train_summary_file.add_summary(summary_out,i)  #save train_summary\n",
    "    if i % 100 == 0:\n",
    "        # success ?\n",
    "        ta, tc = sess.run([accuracy, cost], feed_dict={xs: batch_xs, ys: batch_ys})    #feed train data to tensor fro accuracy and cost\n",
    "        test_data = {xs: mnist.test.images, ys: mnist.test.labels}                             # get new data mnist for test\n",
    "        va, vc, summary_test = sess.run([accuracy, cost, summary_op], feed_dict=test_data)                   #feed test data to tensor for acc and cost\n",
    "        print(\"Step : %d Batch : acc = %.4f loss = %.4f | Test acc = %.4f loss = %.4f\" % (i, ta, tc, va, vc))   #print imformation\n",
    "        test_summary_file.add_summary(summary_test,i)\n",
    "        if va > acc_val:\n",
    "\n",
    "            # Save the variables to disk.\n",
    "            save_path = saver.save(sess, \"./tmp/bestACC\")\n",
    "            print(\"Model saved improve from: {:f}  to {:f}\".format(acc_val,va))\n",
    "            acc_val  = va\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Graph and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/bestACC\n",
      "Step : %d Batch : Test acc = 0.9097\n"
     ]
    }
   ],
   "source": [
    "# delete the current graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# import the graph from the file\n",
    "imported_graph = tf.train.import_meta_graph('./tmp/bestACC.meta')\n",
    "# list all the tensors in the graph\n",
    "with tf.Session() as sess:\n",
    "    initValue = tf.global_variables_initializer()\n",
    "    sess.run(initValue)\n",
    "    imported_graph.restore(sess, './tmp/bestACC')\n",
    "    test_data = {\"inputX:0\":mnist.test.images,\"labelY:0\":mnist.test.labels}\n",
    "    a = sess.run([\"ACC:0\"],feed_dict=test_data)\n",
    "    print(\"Step : %d Batch : Test acc = {:2.4f}\".format(a[0]))   #print information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/bestACC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    imported_graph.restore(sess, './tmp/bestACC')\n",
    "    image = mnist.test.images[0]*255\n",
    "    image = np.reshape(image,[28,28])\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    image = np.reshape(image,[-1,28,28,1])\n",
    "    a = sess.run([\"Y_pre:0\"],feed_dict= {\"inputX:0\":image})\n",
    "    print(a)\n",
    "    print(np.argmax(a[0],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
